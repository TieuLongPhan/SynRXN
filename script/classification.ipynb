{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from synrxn.io.io import save_df_gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. USPTO 50k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Mapping, Any\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _extract_first_str(value: Any) -> Optional[str]:\n",
    "    \"\"\"Return the first non-empty string from a value that may be a string, list, tuple,\n",
    "    or string-encoded list. Returns None for missing/NaN.\"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return None\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        for el in value:\n",
    "            if el is None:\n",
    "                continue\n",
    "            s = str(el).strip()\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        s = value.strip()\n",
    "        # try to parse python literal like \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)) and parsed:\n",
    "                    return str(parsed[0]).strip() or None\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s or None\n",
    "    # fallback\n",
    "    s = str(value).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def uspto_curate(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"uspto_index\",\n",
    "    id_prefix: str = \"USPTO\",\n",
    "    class_col: str = \"new_class\",\n",
    "    reactions_col: str = \"reactions\",\n",
    "    split_col: str = \"split\",\n",
    "    class_map: Optional[Mapping[int, str]] = None,\n",
    "    default_split: str = \"train\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Curate a USPTO-style dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe (must contain `reactions` and `new_class` in typical usage).\n",
    "    id_col : str\n",
    "        Column to use for the numeric/index identifier if present. If absent, df.index is used.\n",
    "    id_prefix : str\n",
    "        Prefix for R-id (final id will be f\"{id_prefix}_{id_value}\").\n",
    "    class_col : str\n",
    "        Column name containing class integers (will be turned into `label`).\n",
    "    reactions_col : str\n",
    "        Column name containing reaction SMILES (renamed to `rxn`).\n",
    "    split_col : str\n",
    "        Column name containing split values (kept as `split` in output).\n",
    "    class_map : Mapping[int, str] or None\n",
    "        Optional mapping to translate numeric classes to human labels. If None, raw class retained.\n",
    "    default_split : str\n",
    "        When `split` column is missing or NaN, fill using this value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Curated dataframe with columns ordered: [\"R-id\", \"rxn\", \"label\", \"split\"].\n",
    "    \"\"\"\n",
    "    df_in = df.copy()\n",
    "\n",
    "    # Check presence of reactions column\n",
    "    if reactions_col not in df_in.columns:\n",
    "        raise ValueError(f\"Input dataframe must contain a '{reactions_col}' column.\")\n",
    "\n",
    "    # Prepare identifier source: either id_col or index\n",
    "    if id_col in df_in.columns:\n",
    "        id_values = df_in[id_col].astype(str)\n",
    "    else:\n",
    "        # use index\n",
    "        id_values = df_in.index.astype(str)\n",
    "\n",
    "    # Build R-id\n",
    "    R_ids = [f\"{id_prefix}_{v}\" for v in id_values]\n",
    "\n",
    "    # Extract rxn (first element if list-like or stringified list)\n",
    "    rxn_series = df_in[reactions_col].apply(_extract_first_str)\n",
    "\n",
    "    # Prepare label column from class_col\n",
    "    if class_col in df_in.columns:\n",
    "        raw_labels = df_in[class_col]\n",
    "        # apply map if provided, otherwise attempt to cast to int where possible\n",
    "        if class_map is not None:\n",
    "            def _map_label(x):\n",
    "                try:\n",
    "                    return class_map.get(int(x), class_map.get(x, x))\n",
    "                except Exception:\n",
    "                    return class_map.get(x, x)\n",
    "            label_series = raw_labels.map(_map_label)\n",
    "        else:\n",
    "            # try int where possible, else leave as-is\n",
    "            def _to_int_or_pass(x):\n",
    "                try:\n",
    "                    if pd.isna(x):\n",
    "                        return None\n",
    "                    return int(x)\n",
    "                except Exception:\n",
    "                    return x\n",
    "            label_series = raw_labels.map(_to_int_or_pass)\n",
    "    else:\n",
    "        # no class column: create label as None\n",
    "        label_series = pd.Series([None] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Prepare split column\n",
    "    if split_col in df_in.columns:\n",
    "        split_series = df_in[split_col].fillna(default_split).astype(str)\n",
    "    else:\n",
    "        split_series = pd.Series([default_split] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Compose output DataFrame\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"R-id\": R_ids,\n",
    "            \"rxn\": rxn_series,\n",
    "            \"label\": label_series,\n",
    "            \"split\": split_series,\n",
    "        },\n",
    "        index=df_in.index,\n",
    "    )\n",
    "\n",
    "    # Reorder and reset index for cleanliness\n",
    "    out = out[[\"R-id\", \"rxn\", \"label\", \"split\"]].reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto_b = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/USPTO_50k_balanced.csv.gz\"\n",
    "uspto_u = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/USPTO_50k_unbalanced.csv.gz\"\n",
    "uspto_u = pd.read_csv(uspto_u, compression=\"gzip\", low_memory=False)\n",
    "uspto_b = pd.read_csv(uspto_b, compression=\"gzip\", low_memory=False)\n",
    "\n",
    "\n",
    "uspto_u = uspto_curate(uspto_u)  \n",
    "uspto_b = uspto_curate(uspto_b) \n",
    "\n",
    "save_df_gz(uspto_u, '../Data/classification/uspto_50k_u.csv.gz')\n",
    "save_df_gz(uspto_b, '../Data/classification/uspto_50k_b.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Schneider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Mapping, Any\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _extract_first_str(value: Any) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Return the first non-empty string from a value that may be a string, list, tuple,\n",
    "    or string-encoded list. Returns None for missing/NaN.\n",
    "    \"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return None\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        for el in value:\n",
    "            if el is None:\n",
    "                continue\n",
    "            s = str(el).strip()\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        s = value.strip()\n",
    "        # try to parse python literal like \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)) and parsed:\n",
    "                    return str(parsed[0]).strip() or None\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s or None\n",
    "    # fallback\n",
    "    s = str(value).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def schneider_curate(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: str = \"schneider_index\",\n",
    "    id_prefix: str = \"sch\",\n",
    "    rxn_col: str = \"rxn\",\n",
    "    split_col: str = \"split\",\n",
    "    y_col: str = \"y\",\n",
    "    class_map: Optional[Mapping[int, str]] = None,\n",
    "    default_split: str = \"train\",\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Curate a Schneider-style dataframe.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe expected to contain at least `rxn` and `y` (or their equivalents).\n",
    "    id_col : str\n",
    "        Column to use for the identifier if present (fallback to df.index when absent).\n",
    "    id_prefix : str\n",
    "        Prefix for the generated R-id (final R-id will be f\"{id_prefix}_{id_value}\").\n",
    "    rxn_col : str\n",
    "        Column containing reaction strings; will be normalized to `rxn` in output.\n",
    "    split_col : str\n",
    "        Column containing split labels; kept as `split`. If missing, filled with `default_split`.\n",
    "    y_col : str\n",
    "        Column containing target integers used to create `label`.\n",
    "    class_map : Mapping[int, str] or None\n",
    "        Optional mapping to translate `y` integer values to textual labels.\n",
    "    default_split : str\n",
    "        Value to use when `split` is missing/NaN.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Curated dataframe with columns ordered: [\"R-id\", \"rxn\", \"label\", \"split\"].\n",
    "    \"\"\"\n",
    "    df_in = df.copy()\n",
    "\n",
    "    # Build identifier values (stringified)\n",
    "    if id_col in df_in.columns:\n",
    "        id_values = df_in[id_col].astype(str)\n",
    "    else:\n",
    "        id_values = df_in.index.astype(str)\n",
    "    R_ids = [f\"{id_prefix}_{v}\" for v in id_values]\n",
    "\n",
    "    # Extract rxn (first element if list-like or stringified list)\n",
    "    if rxn_col not in df_in.columns:\n",
    "        raise ValueError(f\"Input dataframe must contain a '{rxn_col}' column.\")\n",
    "    rxn_series = df_in[rxn_col].apply(_extract_first_str)\n",
    "\n",
    "    # Prepare label from y_col\n",
    "    if y_col in df_in.columns:\n",
    "        raw_y = df_in[y_col]\n",
    "        if class_map is not None:\n",
    "            def _map_y(x):\n",
    "                try:\n",
    "                    return class_map.get(int(x), class_map.get(x, x))\n",
    "                except Exception:\n",
    "                    return class_map.get(x, x)\n",
    "            label_series = raw_y.map(_map_y)\n",
    "        else:\n",
    "            # try to cast to int where possible\n",
    "            def _to_int_or_pass(x):\n",
    "                try:\n",
    "                    if pd.isna(x):\n",
    "                        return None\n",
    "                    return int(x)\n",
    "                except Exception:\n",
    "                    return x\n",
    "            label_series = raw_y.map(_to_int_or_pass)\n",
    "    else:\n",
    "        label_series = pd.Series([None] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Prepare split\n",
    "    if split_col in df_in.columns:\n",
    "        split_series = df_in[split_col].fillna(default_split).astype(str)\n",
    "    else:\n",
    "        split_series = pd.Series([default_split] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Compose output\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"R-id\": R_ids,\n",
    "            \"rxn\": rxn_series,\n",
    "            \"label\": label_series,\n",
    "            \"split\": split_series,\n",
    "        },\n",
    "        index=df_in.index,\n",
    "    )\n",
    "\n",
    "    out = out[[\"R-id\", \"rxn\", \"label\", \"split\"]].reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schneider_b = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/schneider50k_balanced.csv.gz\"\n",
    "schneider_u = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/schneider50k_unbalanced.csv.gz\"\n",
    "\n",
    "schneider_u = pd.read_csv(schneider_u, compression=\"gzip\", low_memory=False)\n",
    "schneider_b = pd.read_csv(schneider_b, compression=\"gzip\", low_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "schneider_u = schneider_curate(schneider_u)  \n",
    "schneider_b = schneider_curate(schneider_b, rxn_col='reactions') \n",
    "\n",
    "save_df_gz(schneider_u, '../Data/classification/schneider_u.csv.gz')\n",
    "save_df_gz(schneider_b, '../Data/classification/schneider_b.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. TPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Mapping, Any\n",
    "import pandas as pd\n",
    "import ast\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _extract_first_str(value: Any) -> Optional[str]:\n",
    "    \"\"\"Return the first non-empty string from value which may be:\n",
    "       - a string\n",
    "       - a list/tuple of strings\n",
    "       - a stringified python list \"['a','b']\"\n",
    "       - None / NaN -> returns None\n",
    "    \"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return None\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        for el in value:\n",
    "            if el is None:\n",
    "                continue\n",
    "            s = str(el).strip()\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        s = value.strip()\n",
    "        # try to parse stringified list/tuple like \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)) and parsed:\n",
    "                    return str(parsed[0]).strip() or None\n",
    "            except Exception:\n",
    "                # fall back to raw string\n",
    "                pass\n",
    "        return s or None\n",
    "    # fallback coercion\n",
    "    s = str(value).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def rxnclass_curate(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col: Optional[str] = None,\n",
    "    id_prefix: str = \"RXN\",\n",
    "    rxn_col: str = \"rxn\",\n",
    "    class_col: str = \"rxn_class\",\n",
    "    split_col: str = \"split\",\n",
    "    class_map: Optional[Mapping[int, str]] = None,\n",
    "    default_split: str = \"train\",\n",
    "    zero_pad: Optional[int] = None,\n",
    "    keep_orig_index: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Curate dataframe where `rxn_class` should be converted to `label`.\n",
    "\n",
    "    Returns DataFrame with columns in this exact order:\n",
    "      [\"R-id\", \"rxn\", \"label\", \"split\"]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame; expected to contain at least `rxn` and `rxn_class`.\n",
    "    id_col :\n",
    "        Optional column to use for id values. If None or not present, df.index is used.\n",
    "    id_prefix :\n",
    "        Prefix for R-id, final form is f\"{id_prefix}_{id_value}\" (id_value stringified).\n",
    "    rxn_col :\n",
    "        Column name holding reaction strings (list-like or string). Extracted to `rxn`.\n",
    "    class_col :\n",
    "        Column name holding class identifiers; will be converted to `label`.\n",
    "    split_col :\n",
    "        Column name for dataset split (kept as `split`). Missing entries are filled with `default_split`.\n",
    "    class_map :\n",
    "        Optional mapping {int: str} to translate numeric class -> label. If None, attempt to cast to int else keep raw.\n",
    "    default_split :\n",
    "        String to fill `split` when missing.\n",
    "    zero_pad :\n",
    "        If provided (e.g. 6), zero-pad the numeric id portion: RXN_000123. If id_col values are non-numeric, zero_pad is ignored.\n",
    "    keep_orig_index :\n",
    "        If True, include a column \"orig_index\" with the original dataframe index to aid traceability.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Curated dataframe with ordered columns [\"R-id\",\"rxn\",\"label\",\"split\"].\n",
    "    \"\"\"\n",
    "    df_in = df.copy()\n",
    "\n",
    "    # Validate presence of rxn column\n",
    "    if rxn_col not in df_in.columns:\n",
    "        raise ValueError(f\"Input dataframe must contain a '{rxn_col}' column.\")\n",
    "\n",
    "    # Build id values\n",
    "    if id_col and id_col in df_in.columns:\n",
    "        id_vals = df_in[id_col].astype(str)\n",
    "    else:\n",
    "        id_vals = df_in.index.astype(str)\n",
    "\n",
    "    # Optionally zero-pad numeric ids\n",
    "    def _maybe_pad(v: str) -> str:\n",
    "        if zero_pad is None:\n",
    "            return v\n",
    "        try:\n",
    "            iv = int(v)\n",
    "            return str(iv).zfill(zero_pad)\n",
    "        except Exception:\n",
    "            return v  # cannot pad non-numeric ids\n",
    "\n",
    "    R_ids = [f\"{id_prefix}_{_maybe_pad(v)}\" for v in id_vals]\n",
    "\n",
    "    # Extract rxn\n",
    "    rxn_series = df_in[rxn_col].apply(_extract_first_str)\n",
    "\n",
    "    # Convert rxn_class -> label\n",
    "    if class_col in df_in.columns:\n",
    "        raw_cls = df_in[class_col]\n",
    "\n",
    "        if class_map is not None:\n",
    "            def _map_fn(x):\n",
    "                try:\n",
    "                    return class_map.get(int(x), class_map.get(x, x))\n",
    "                except Exception:\n",
    "                    return class_map.get(x, x)\n",
    "            label_series = raw_cls.map(_map_fn)\n",
    "        else:\n",
    "            # try cast to int, otherwise keep raw\n",
    "            def _to_int_or_pass(x):\n",
    "                try:\n",
    "                    if pd.isna(x):\n",
    "                        return None\n",
    "                    return int(x)\n",
    "                except Exception:\n",
    "                    return x\n",
    "            label_series = raw_cls.map(_to_int_or_pass)\n",
    "    else:\n",
    "        label_series = pd.Series([None] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Prepare split\n",
    "    if split_col in df_in.columns:\n",
    "        split_series = df_in[split_col].fillna(default_split).astype(str)\n",
    "    else:\n",
    "        split_series = pd.Series([default_split] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # Compose final DataFrame\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"R-id\": R_ids,\n",
    "            \"rxn\": rxn_series,\n",
    "            \"label\": label_series,\n",
    "            \"split\": split_series,\n",
    "        },\n",
    "        index=df_in.index,\n",
    "    )\n",
    "\n",
    "    if keep_orig_index:\n",
    "        out.insert(0, \"orig_index\", df_in.index)\n",
    "\n",
    "    out = out[[\"R-id\", \"rxn\", \"label\", \"split\"]].reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpl_b = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/USPTO_TPL_balanced.csv.gz\"\n",
    "tpl_u = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/USPTO_TPL_unbalanced.csv.gz\"\n",
    "\n",
    "tpl_u = pd.read_csv(tpl_u, compression=\"gzip\", low_memory=False)\n",
    "tpl_u =  rxnclass_curate(tpl_u, id_prefix=\"tpl\", zero_pad=6, class_map=None)\n",
    "\n",
    "tpl_b = pd.read_csv(tpl_b, compression=\"gzip\", low_memory=False)\n",
    "tpl_b =  rxnclass_curate(tpl_b, id_prefix=\"tpl\", zero_pad=6, class_map=None)\n",
    "\n",
    "save_df_gz(schneider_u, '../Data/classification/tpl_u.csv.gz')\n",
    "save_df_gz(schneider_b, '../Data/classification/tpl_b.csv.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. SynTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Any, List, Sequence\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def _extract_first_str(value: Any) -> Optional[str]:\n",
    "    \"\"\"Return first non-empty string from value which may be a str, list/tuple,\n",
    "    or string-encoded list. Return None for missing/NaN.\"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return None\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        for el in value:\n",
    "            if el is None:\n",
    "                continue\n",
    "            s = str(el).strip()\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        s = value.strip()\n",
    "        # try parse python literal list/tuple e.g. \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)) and parsed:\n",
    "                    return str(parsed[0]).strip() or None\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s or None\n",
    "    s = str(value).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def _first_present_column(df: pd.DataFrame, candidates: Sequence[str]) -> Optional[str]:\n",
    "    \"\"\"Return the first candidate that exists in df.columns (case-sensitive).\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _try_int(v: Any) -> Optional[int]:\n",
    "    \"\"\"Attempt to cast to int; return None if NaN or casting fails.\"\"\"\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return None\n",
    "    try:\n",
    "        return int(v)\n",
    "    except Exception:\n",
    "        try:\n",
    "            # sometimes values are string numbers with spaces\n",
    "            s = str(v).strip()\n",
    "            return int(s)\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "def syntemp_curate(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col_candidates: Optional[List[str]] = None,\n",
    "    rsmicol_candidates: Optional[List[str]] = None,\n",
    "    newr0_candidates: Optional[List[str]] = None,\n",
    "    newr1_candidates: Optional[List[str]] = None,\n",
    "    newr2_candidates: Optional[List[str]] = None,\n",
    "    id_prefix: str = \"SYN\",\n",
    "    zero_pad: Optional[int] = None,\n",
    "    keep_orig_index: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Curate a 'syntemp' DataFrame into columns:\n",
    "      [\"R-id\", \"rxn\", \"label_0\", \"label_1\", \"label_2\"]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df\n",
    "        Input DataFrame (expects at least R_ID/R-ID and RSMI and New_R0/1/2 or variants).\n",
    "    id_col_candidates\n",
    "        Ordered list of candidate column names to use for the id (default: ['R_ID','R_ID','R-id','R-ID','R_ID']).\n",
    "    rsmicol_candidates\n",
    "        Candidate names for reaction column (default: ['RSMI','RsmI','R_smI','RSMI','RsmI','RSMI']).\n",
    "    newr0_candidates, newr1_candidates, newr2_candidates\n",
    "        Candidate names for label columns; defaults accept common naming variants.\n",
    "    id_prefix\n",
    "        Prefix for the produced R-id e.g. \"SYN\" -> \"SYN_123\".\n",
    "    zero_pad\n",
    "        If provided, zero-pad numeric id portion to this width (non-numeric ids are left unchanged).\n",
    "    keep_orig_index\n",
    "        If True, include an \"orig_index\" column with the original dataframe index.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Curated DataFrame with ordered columns [\"R-id\",\"rxn\",\"label_0\",\"label_1\",\"label_2\"] (and optionally \"orig_index\").\n",
    "    \"\"\"\n",
    "    df_in = df.copy()\n",
    "\n",
    "    # default candidate lists\n",
    "    if id_col_candidates is None:\n",
    "        id_col_candidates = [\"R_ID\", \"R-ID\", \"R-id\", \"R_ID\", \"R_ID\"]\n",
    "    if rsmicol_candidates is None:\n",
    "        rsmicol_candidates = [\"RSMI\", \"RsmI\", \"RSMI\", \"R_smI\", \"rxn\", \"reaction\"]\n",
    "    if newr0_candidates is None:\n",
    "        newr0_candidates = [\"New_R0\", \"NewR0\", \"New_R_0\", \"New0\"]\n",
    "    if newr1_candidates is None:\n",
    "        newr1_candidates = [\"New_R1\", \"NewR1\", \"New_R_1\", \"New1\"]\n",
    "    if newr2_candidates is None:\n",
    "        newr2_candidates = [\"New_R2\", \"NewR2\", \"New_R_2\", \"New2\"]\n",
    "\n",
    "    # pick columns that exist\n",
    "    id_col = _first_present_column(df_in, id_col_candidates)\n",
    "    rsmicol = _first_present_column(df_in, rsmicol_candidates)\n",
    "    c_newr0 = _first_present_column(df_in, newr0_candidates)\n",
    "    c_newr1 = _first_present_column(df_in, newr1_candidates)\n",
    "    c_newr2 = _first_present_column(df_in, newr2_candidates)\n",
    "\n",
    "    # prepare id values (use provided id col or index)\n",
    "    if id_col is not None:\n",
    "        id_vals = df_in[id_col].astype(str)\n",
    "    else:\n",
    "        id_vals = df_in.index.astype(str)\n",
    "\n",
    "    # optional zero-pad numeric ids\n",
    "    def _maybe_pad_val(v: str) -> str:\n",
    "        if zero_pad is None:\n",
    "            return v\n",
    "        try:\n",
    "            iv = int(v)\n",
    "            return str(iv).zfill(zero_pad)\n",
    "        except Exception:\n",
    "            return v\n",
    "\n",
    "    R_ids = [f\"{id_prefix}_{_maybe_pad_val(v)}\" for v in id_vals]\n",
    "\n",
    "    # rxn extraction\n",
    "    if rsmicol is None:\n",
    "        # try lowercase alternatives\n",
    "        lowcols = [c for c in df_in.columns if c.lower() == \"rsmI\".lower()]\n",
    "        rsmicol = lowcols[0] if lowcols else None\n",
    "\n",
    "    if rsmicol is None:\n",
    "        raise ValueError(\"Could not find reaction column (candidates: {}).\".format(rsmicol_candidates))\n",
    "\n",
    "    rxn_series = df_in[rsmicol].apply(_extract_first_str)\n",
    "\n",
    "    # labels: try to cast New_R* -> int when possible, else keep None or raw\n",
    "    def _get_label_series(col_name: Optional[str]) -> pd.Series:\n",
    "        if col_name is None or col_name not in df_in.columns:\n",
    "            return pd.Series([None] * len(df_in), index=df_in.index)\n",
    "        raw = df_in[col_name]\n",
    "        # if list-like (string encoded), extract first then try int\n",
    "        extracted = raw.map(_extract_first_str)\n",
    "        casted = extracted.map(lambda v: _try_int(v))\n",
    "        # if cast failed for many values, fallback to extracted strings\n",
    "        # but keep ints where they succeeded\n",
    "        return casted\n",
    "\n",
    "    label_0 = _get_label_series(c_newr0)\n",
    "    label_1 = _get_label_series(c_newr1)\n",
    "    label_2 = _get_label_series(c_newr2)\n",
    "\n",
    "    # build output\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"R-id\": R_ids,\n",
    "            \"rxn\": rxn_series,\n",
    "            \"label_0\": label_0.values,\n",
    "            \"label_1\": label_1.values,\n",
    "            \"label_2\": label_2.values,\n",
    "        },\n",
    "        index=df_in.index,\n",
    "    )\n",
    "\n",
    "    if keep_orig_index:\n",
    "        out.insert(0, \"orig_index\", df_in.index)\n",
    "\n",
    "    # ensure exact ordering\n",
    "    final_cols = [\"R-id\", \"rxn\", \"label_0\", \"label_1\", \"label_2\"]\n",
    "    out = out[final_cols].reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "syntemp = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/Syntemp_cluster.csv.gz\"\n",
    "\n",
    "syntemp =  pd.read_csv(syntemp, compression=\"gzip\", low_memory=False)\n",
    "syntemp = syntemp_curate(syntemp, id_prefix='syntemp', keep_orig_index=True)\n",
    "save_df_gz(syntemp, '../Data/classification/syntemp.csv.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. ECREACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Sequence, Any\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "\n",
    "def _extract_first_str(value: Any) -> Optional[str]:\n",
    "    \"\"\"Return the first non-empty string from value which may be:\n",
    "       - a plain string\n",
    "       - a list/tuple of strings\n",
    "       - a stringified python list \"['a','b']\"\n",
    "       - None / NaN -> returns None\n",
    "    \"\"\"\n",
    "    if value is None or (isinstance(value, float) and pd.isna(value)):\n",
    "        return None\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        for el in value:\n",
    "            if el is None:\n",
    "                continue\n",
    "            s = str(el).strip()\n",
    "            if s:\n",
    "                return s\n",
    "        return None\n",
    "    if isinstance(value, str):\n",
    "        s = value.strip()\n",
    "        # try to parse python literal list/tuple e.g. \"['a','b']\"\n",
    "        if (s.startswith(\"[\") and s.endswith(\"]\")) or (s.startswith(\"(\") and s.endswith(\")\")):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(s)\n",
    "                if isinstance(parsed, (list, tuple)) and parsed:\n",
    "                    return str(parsed[0]).strip() or None\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s or None\n",
    "    s = str(value).strip()\n",
    "    return s if s else None\n",
    "\n",
    "\n",
    "def _first_present_column(df: pd.DataFrame, candidates: Sequence[str]) -> Optional[str]:\n",
    "    \"\"\"Return the first candidate column name that exists in df.columns.\"\"\"\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "\n",
    "def _try_int(v: Any) -> Optional[int]:\n",
    "    \"\"\"Try to cast v to int; return None for NaN or on failure.\"\"\"\n",
    "    if v is None or (isinstance(v, float) and pd.isna(v)):\n",
    "        return None\n",
    "    try:\n",
    "        return int(v)\n",
    "    except Exception:\n",
    "        try:\n",
    "            return int(str(v).strip())\n",
    "        except Exception:\n",
    "            return None\n",
    "\n",
    "\n",
    "def claire_curate(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    id_col_candidates: Optional[Sequence[str]] = None,\n",
    "    rxn_col_candidates: Optional[Sequence[str]] = None,\n",
    "    ec1_col_candidates: Optional[Sequence[str]] = None,\n",
    "    ec2_col_candidates: Optional[Sequence[str]] = None,\n",
    "    ec3_col_candidates: Optional[Sequence[str]] = None,\n",
    "    id_prefix: str = \"ecreact\",\n",
    "    zero_pad: Optional[int] = None,\n",
    "    default_split: str = \"train\",\n",
    "    keep_orig_index: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Curate Claire-style dataframe.\n",
    "\n",
    "    Transformations performed:\n",
    "      - Build R-id as f\"{id_prefix}_{index_value}\" where index_value comes from a chosen id column\n",
    "        (default candidates include 'index') or df.index if none found.\n",
    "      - rxn_smiles -> rxn (extract first element if list-like or stringified list)\n",
    "      - ec1_encode -> ec1, ec2_encode -> ec2, ec3_encode -> ec3 (fallback to ec1/ec2/ec3 if encode cols missing)\n",
    "      - keep `split` column (fill with default_split when missing)\n",
    "\n",
    "    Output columns (in this order):\n",
    "      [\"R-id\", \"rxn\", \"ec1\", \"ec2\", \"ec3\", \"split\"]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe expected to contain columns like 'rxn_smiles', 'ec*_encode' and 'split'.\n",
    "    id_col_candidates : sequence[str], optional\n",
    "        Candidate column names to use as the numeric id. Defaults to ['index', 'Index'] then falls back to df.index.\n",
    "    rxn_col_candidates : sequence[str], optional\n",
    "        Candidate names for reaction smiles column. Defaults to ['rxn_smiles', 'rxn', 'reaction'].\n",
    "    ec1_col_candidates/ec2_col_candidates/ec3_col_candidates : sequence[str], optional\n",
    "        Candidate names for encoded enzyme class columns. Defaults prefer 'ec1_encode' etc., then 'ec1'.\n",
    "    id_prefix : str\n",
    "        Prefix for generated R-id (default 'claire').\n",
    "    zero_pad : int or None\n",
    "        If provided and id value is numeric, zero-pad to this width.\n",
    "    default_split : str\n",
    "        Value used to fill missing split entries.\n",
    "    keep_orig_index : bool\n",
    "        If True, an 'orig_index' column with the original df.index is included at start.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Curated DataFrame with columns [\"R-id\", \"rxn\", \"ec1\", \"ec2\", \"ec3\", \"split\"].\n",
    "    \"\"\"\n",
    "    df_in = df.copy()\n",
    "\n",
    "    # sensible defaults\n",
    "    if id_col_candidates is None:\n",
    "        id_col_candidates = [\"index\", \"Index\"]\n",
    "    if rxn_col_candidates is None:\n",
    "        rxn_col_candidates = [\"rxn_smiles\", \"rxn_smiles\", \"rxn\", \"reaction\"]\n",
    "    if ec1_col_candidates is None:\n",
    "        ec1_col_candidates = [\"ec1_encode\", \"ec1encode\", \"ec1_encode\", \"ec1\"]\n",
    "    if ec2_col_candidates is None:\n",
    "        ec2_col_candidates = [\"ec2_encode\", \"ec2encode\", \"ec2_encode\", \"ec2\"]\n",
    "    if ec3_col_candidates is None:\n",
    "        ec3_col_candidates = [\"ec3_encode\", \"ec3encode\", \"ec3_encode\", \"ec3\"]\n",
    "\n",
    "    # pick id source\n",
    "    id_col = _first_present_column(df_in, id_col_candidates)\n",
    "    if id_col is not None:\n",
    "        id_vals = df_in[id_col].astype(str)\n",
    "    else:\n",
    "        id_vals = df_in.index.astype(str)\n",
    "\n",
    "    # optional zero-pad numeric ids\n",
    "    def _maybe_pad(v: str) -> str:\n",
    "        if zero_pad is None:\n",
    "            return v\n",
    "        try:\n",
    "            iv = int(v)\n",
    "            return str(iv).zfill(zero_pad)\n",
    "        except Exception:\n",
    "            return v\n",
    "\n",
    "    R_ids = [f\"{id_prefix}_{_maybe_pad(v)}\" for v in id_vals]\n",
    "\n",
    "    # rxn extraction\n",
    "    rxn_col = _first_present_column(df_in, rxn_col_candidates)\n",
    "    if rxn_col is None:\n",
    "        raise ValueError(f\"Could not find a reaction column (candidates: {rxn_col_candidates}).\")\n",
    "    rxn_series = df_in[rxn_col].apply(_extract_first_str)\n",
    "\n",
    "    # ec columns mapping: prefer ec?_encode then ec?\n",
    "    ec1_col = _first_present_column(df_in, ec1_col_candidates)\n",
    "    ec2_col = _first_present_column(df_in, ec2_col_candidates)\n",
    "    ec3_col = _first_present_column(df_in, ec3_col_candidates)\n",
    "\n",
    "    def _get_ec_series(col_name: Optional[str]) -> pd.Series:\n",
    "        if col_name is None or col_name not in df_in.columns:\n",
    "            return pd.Series([None] * len(df_in), index=df_in.index)\n",
    "        # if values look list-like / stringified, extract first string then try int\n",
    "        extracted = df_in[col_name].map(_extract_first_str)\n",
    "        casted = extracted.map(lambda v: _try_int(v))\n",
    "        # prefer int when possible, otherwise keep extracted string\n",
    "        # we return the int series (may contain None)\n",
    "        return casted\n",
    "\n",
    "    ec1_series = _get_ec_series(ec1_col)\n",
    "    ec2_series = _get_ec_series(ec2_col)\n",
    "    ec3_series = _get_ec_series(ec3_col)\n",
    "\n",
    "    # split: keep as-is but fill missing with default_split\n",
    "    if \"split\" in df_in.columns:\n",
    "        split_series = df_in[\"split\"].fillna(default_split).astype(str)\n",
    "    else:\n",
    "        split_series = pd.Series([default_split] * len(df_in), index=df_in.index)\n",
    "\n",
    "    # assemble output\n",
    "    out = pd.DataFrame(\n",
    "        {\n",
    "            \"R-id\": R_ids,\n",
    "            \"rxn\": rxn_series,\n",
    "            \"ec1\": ec1_series.values,\n",
    "            \"ec2\": ec2_series.values,\n",
    "            \"ec3\": ec3_series.values,\n",
    "            \"split\": split_series.values,\n",
    "        },\n",
    "        index=df_in.index,\n",
    "    )\n",
    "\n",
    "    if keep_orig_index:\n",
    "        out.insert(0, \"orig_index\", df_in.index)\n",
    "\n",
    "    # ensure ordering and reset index\n",
    "    final_cols = [\"R-id\", \"rxn\", \"ec1\", \"ec2\", \"ec3\", \"split\"]\n",
    "    out = out[final_cols].reset_index(drop=True)\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "claire = \"https://raw.githubusercontent.com/phuocchung123/SynCat/main/Data/raw/claire_full.csv.gz\"\n",
    "\n",
    "claire =  pd.read_csv(claire, compression=\"gzip\", low_memory=False)\n",
    "claire = claire_curate(claire)\n",
    "save_df_gz(claire, '../Data/classification/ecreact.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnxdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
