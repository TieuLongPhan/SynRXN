{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import logging\n",
    "from typing import Any, Callable, Dict, Iterable, List, Optional, Tuple, Union\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from synkit.Chem.Reaction.standardize import Standardize\n",
    "from synkit.Chem.Reaction.canon_rsmi import CanonRSMI\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def process_aam(\n",
    "    entries: Iterable[Dict[str, Any]],\n",
    "    *,\n",
    "    rxn_fn: Optional[Callable[[Any], Any]] = None,\n",
    "    canon_fn: Optional[Callable[[Any], Any]] = None,\n",
    "    std: Optional[Standardize] = None,\n",
    "    canon: Optional[CanonRSMI] = None,\n",
    "    reactions_key: str = \"reactions\",\n",
    "    rxn_key: str = \"rxn\",\n",
    "    gt_key: str = \"ground_truth\",\n",
    "    inplace: bool = False,\n",
    "    swallow_exceptions: bool = True,\n",
    "    return_failures: bool = False,\n",
    "    progress: bool = True,\n",
    "    progress_desc: Optional[str] = None,\n",
    "    progress_disable: Optional[bool] = False,\n",
    ") -> Union[List[Dict[str, Any]], Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]]:\n",
    "    if inplace:\n",
    "        working: List[Dict[str, Any]] = entries  # type: ignore[assignment]\n",
    "    else:\n",
    "        working = [dict(e) for e in entries]\n",
    "\n",
    "    if rxn_fn is None:\n",
    "        if std is None:\n",
    "            std = Standardize()\n",
    "        rxn_fn = lambda reactions: std.fit(reactions)\n",
    "\n",
    "    if canon_fn is None:\n",
    "        if canon is None:\n",
    "            canon = CanonRSMI(backend=\"wl\", wl_iterations=3)\n",
    "        def _canon_fn(gt_val: Any) -> Any:\n",
    "            if gt_val is None:\n",
    "                return None\n",
    "            return canon.canonicalise(gt_val).canonical_rsmi\n",
    "        canon_fn = _canon_fn\n",
    "\n",
    "    processed: List[Dict[str, Any]] = []\n",
    "    failures: List[Dict[str, Any]] = []\n",
    "\n",
    "    iterator = working\n",
    "    if progress:\n",
    "        total = None\n",
    "        try:\n",
    "            total = len(working)  # type: ignore[arg-type]\n",
    "        except Exception:\n",
    "            total = None\n",
    "        iterator = tqdm(working, desc=(progress_desc or \"process_aam\"), disable=progress_disable, total=total)\n",
    "\n",
    "    for idx, entry in enumerate(iterator):\n",
    "        try:\n",
    "            raw_reactions = entry.get(reactions_key)\n",
    "            entry[rxn_key] = rxn_fn(raw_reactions)\n",
    "            if gt_key in entry and entry.get(gt_key) is not None:\n",
    "                entry[gt_key] = canon_fn(entry[gt_key])\n",
    "        except Exception as exc:\n",
    "            log.debug(\"process_aam: error processing entry %s: %s\", idx, exc, exc_info=True)\n",
    "            if swallow_exceptions:\n",
    "                entry[rxn_key] = None\n",
    "                entry[gt_key] = None\n",
    "                failures.append({\"index\": idx, \"entry\": dict(entry), \"error\": exc})\n",
    "            else:\n",
    "                raise\n",
    "\n",
    "        if entry.get(rxn_key):\n",
    "            entry.pop(reactions_key, None)\n",
    "            processed.append(entry)\n",
    "\n",
    "    if progress:\n",
    "        try:\n",
    "            iterator.close()\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if inplace:\n",
    "        try:\n",
    "            entries.clear()  # type: ignore[attr-defined]\n",
    "            entries.extend(processed)  # type: ignore[arg-type]\n",
    "        except Exception:\n",
    "            log.debug(\"Could not replace original 'entries' in-place; returning processed list.\")\n",
    "\n",
    "    if return_failures:\n",
    "        return processed, failures\n",
    "\n",
    "    return processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from synrxn.io.io import load_json_from_raw_github, load_df_gz, save_df_gz\n",
    "from synkit.IO import configure_warnings_and_logs\n",
    "configure_warnings_and_logs(True, True)\n",
    "ecoli = \"https://raw.githubusercontent.com/TieuLongPhan/SynTemp/main/Data/AAM/results_benchmark/ecoli/ecoli_aam_reactions.json.gz\"\n",
    "recond3d = \"https://raw.githubusercontent.com/TieuLongPhan/SynTemp/main/Data/AAM/results_benchmark/recon3d/recon3d_aam_reactions.json.gz\"\n",
    "golden = \"https://raw.githubusercontent.com/TieuLongPhan/SynTemp/main/Data/AAM/results_benchmark/golden/golden_aam_reactions.json.gz\"\n",
    "natcomm = \"https://raw.githubusercontent.com/TieuLongPhan/SynTemp/main/Data/AAM/results_benchmark/natcomm/natcomm_aam_reactions.json.gz\"\n",
    "uspto3k = \"https://raw.githubusercontent.com/TieuLongPhan/SynTemp/main/Data/AAM/results_benchmark/uspto_3k/uspto_3k_aam_reactions.json.gz\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ecoli = load_json_from_raw_github(ecoli, as_frame=False)\n",
    "ecoli = process_aam(ecoli, progress=True, rxn_key='rxn')\n",
    "print(len(ecoli))\n",
    "save_df_gz(pd.DataFrame(ecoli), '../Data/aam/ecoli.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recond3d = load_json_from_raw_github(recond3d, as_frame=False)\n",
    "recond3d = process_aam(recond3d)\n",
    "print(len(recond3d))\n",
    "save_df_gz(pd.DataFrame(recond3d), '../Data/aam/ecoli.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "golden = load_json_from_raw_github(golden, as_frame=False)\n",
    "golden = process_aam(golden)\n",
    "print(len(golden))\n",
    "save_df_gz(pd.DataFrame(golden), '../Data/aam/ecoli.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natcomm = load_json_from_raw_github(natcomm, as_frame=False)\n",
    "natcomm = process_aam(natcomm)\n",
    "print(len(natcomm))\n",
    "save_df_gz(pd.DataFrame(natcomm), '../Data/aam/ecoli.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uspto3k = load_json_from_raw_github(uspto3k, as_frame=False)\n",
    "uspto3k = process_aam(uspto3k)\n",
    "print(len(uspto3k))\n",
    "save_df_gz(pd.DataFrame(uspto3k), '../Data/aam/ecoli.csv.gz')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rnxdb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
